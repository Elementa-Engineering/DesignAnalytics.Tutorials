{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67fee91",
   "metadata": {},
   "source": [
    "## First, authenticate to the API\n",
    "\n",
    "All things Characteriazation, Sensitivity and Parametric analysis require that this Software Developement Kit (SDK) be authenticated to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95670e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_schema import APIClient, Space\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# typical block to authenticate to the API\n",
    "client = APIClient(api_url=\"https://api.elementa.nyc\")\n",
    "client.whoami()  # shows that you are properly authenticated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74d840",
   "metadata": {},
   "source": [
    "Next, we list the possible weather files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3825ebf",
   "metadata": {},
   "source": [
    "# Create the design space\n",
    "\n",
    "The design space is create below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"WWR\": 0.4,\n",
    "    \"WINU\": 0.38,\n",
    "    \"WINSHGC\": 0.4,\n",
    "    \"ROOFR\": 35,\n",
    "    \"WALLR\": 20,\n",
    "    \"INFIL\": 0.07,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea114fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = Space(\n",
    "    categoricals=[\n",
    "        dict(\n",
    "            name=\"WWR\",\n",
    "            categories=(0.35, 0.4, 0.45, 0.5, 0.55),\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"WINU\",\n",
    "            categories=(0.17, 0.25, 0.32, 0.38),\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"WINSHGC\",\n",
    "            categories=(0.2, 0.25, 0.3, 0.35, 0.4),\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"ROOFR\",\n",
    "            categories=(30, 35, 40, 50),\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"WALLR\",\n",
    "            categories=(10, 15, 20, 25, 30),\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"INFIL\",\n",
    "            categories=(0.01, 0.04, 0.07),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_schema.space.design_space import SupportedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(SupportedParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63808a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportedParameter[\"INFIL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(SupportedParameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c0391",
   "metadata": {},
   "source": [
    "## Batch Simulation\n",
    "\n",
    "### Prepare the seed model for the API\n",
    "\n",
    "Model must be in \"world\" coordinates. There is a function for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd61022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archetypal import IDF\n",
    "\n",
    "idf = IDF(\"Dynamic_20220908_v2.idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.to_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c15092",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c9341",
   "metadata": {},
   "source": [
    "### Replace the DesignDay components\n",
    "\n",
    "First, we delete the \"SizingPeriod:DesignDay\" components that are in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dds = idf.idfobjects[\"SizingPeriod:DesignDay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be394b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.removeidfobjects(list(dds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275f861",
   "metadata": {},
   "source": [
    "To confirm that the objects were indeed deleted, below shows an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f904ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.idfobjects[\"SizingPeriod:DesignDay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8573d8",
   "metadata": {},
   "source": [
    "We will now the design day file that corresponds to our EPW file and load it as a sring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"DDY/usa_ca_mountain.view-moffett.federal.field.745090_tmy3_rcp45_2041to2060_10per.ddy\"\n",
    ") as f:\n",
    "    dd_str = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830666b3",
   "metadata": {},
   "source": [
    "Then, we call `idf.add_idf_object_from_idf_string` with the dd_str as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.add_idf_object_from_idf_string(dd_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716800f",
   "metadata": {},
   "source": [
    "With archetypal, all the modification we made live in the *memory*, therefore we need to save the model to apply changes for the subsquent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be14ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.saveas(\"Dynamic_20220908_v2.idf\", inplace=True)  # overwrites the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec448e6",
   "metadata": {},
   "source": [
    "Optionally, we can also simulate the model *locally* (as oppsosed to AWS) to make sure the model runs. Passing the option `design_day=True` to the `simulate` command will ensure that we are not running the whole year of simulation but just the design days. It is just faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f697be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idf.simulate(\n",
    "    epw=\"Weather/USA_CA_Mountain.View-Moffett.Federal.Field.745090_TMY3_rcp85_2081to2099_10per.epw\",\n",
    "    design_day=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7e3ab",
   "metadata": {},
   "source": [
    "Energyplus produces a lot of files for our simulation. To keep things tidy and not to fill up the jupyter hub with junk, we can call a linux command to delete the cache folder, where all simulation results reside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d061e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rv cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5c653",
   "metadata": {},
   "source": [
    "## Create Job and Submit\n",
    "\n",
    "Next, we create a BuildingAnalysis object which contains our design space, baseline and defines other parameters for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125644aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(ROTATE=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e73e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"ROTATE\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77266ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(\n",
    "    ROTATE=0,\n",
    "    THERMALMASS=0.0,\n",
    "    WWR=0.6,\n",
    "    SHADING_OVERHANG_PROJECTION=0.001,\n",
    "    WINU=0.36,\n",
    "    WINSHGC=0.32,\n",
    "    ROOFR=31,\n",
    "    WALLR=14,\n",
    "    SCALE_X=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_schema import BuildingAnalysis\n",
    "\n",
    "analysis_1 = BuildingAnalysis(\n",
    "    company=\"Confidential\",\n",
    "    project=\"Dynamic\",\n",
    "    local_epw=\"Weather/USA_CA_Mountain.View-Moffett.Federal.Field.745090_TMY3_rcp85_2081to2099_10per.epw\",\n",
    "    local_seed_model=\"Dynamic_20220908_v2.idf\",\n",
    "    design_space=space,\n",
    "    baseline={\n",
    "        \"WWR\": 0.4,\n",
    "        \"WINU\": 0.38,\n",
    "        \"WINSHGC\": 0.4,\n",
    "        \"ROOFR\": 35,\n",
    "        \"WALLR\": 20,\n",
    "        \"INFIL\": 0.07,\n",
    "    },\n",
    "    analysis_id=\"ea3c4f33-174b-4427-90c1-bc2675d2cd05\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c616d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.analysis_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7564580",
   "metadata": {},
   "source": [
    "### Determining the samples or runs to simulate\n",
    "\n",
    "In this particular project, we are only interested in runnning the sensitivity runs. Therefore, we are going to assing result of the `create_sensitivity_space` method to the `BuildingAnalysis.sampled_space` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab375b64",
   "metadata": {},
   "source": [
    "Our Sampeld space looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.sampled_space = analysis_1.create_lhs_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.sampled_space.pretty_bubble_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.sampled_space.to_df().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de437f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_space = analysis_1.create_space(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_space.pretty_bubble_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45261eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.sampled_space.pretty_bubble_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.sampled_space.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452b718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = analysis_1.sampled_space.pretty_bubble_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858e3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83ccd148",
   "metadata": {},
   "source": [
    "### Preparing the job\n",
    "\n",
    "Based on the above, prapering the job creates all the required information needed to submit a job to AWS Bacth. First, your EPW file and your seed model are going to be uploaded to AWS S3. Then a parameter file very similar to the `sampled_space.to_df()` table above is also uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.prepare_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in analysis_1.job:\n",
    "    job.containerOverrides.resourceRequirements[0].value = \"4048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcc81b",
   "metadata": {},
   "source": [
    "### Sumitting the job\n",
    "\n",
    "Next we can submit the job to AWS. Below, the command returns a `SubmitJobResponse` with some information on the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d37e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_1.submit_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f11737",
   "metadata": {},
   "source": [
    "### Tracking the job status\n",
    "\n",
    "You can track the job status by calling the `track_status` method. This function will *run* in the notebook until all jobs are **COMPLETED** or **FAILED**.\n",
    "\n",
    "If you wish to relieve the notebook to continue working while AWS does its thing, you can interrupt the kernel (⬛) and you will be asked if you wish to terminate the job of not. By the way, after a job has been submitted, you can terminate the job by calling `BuildingAnalysis.terminate_job()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_1.track_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69f815",
   "metadata": {},
   "source": [
    "## What if some or all runs are failing?\n",
    "\n",
    "If runs are failing, you can call the `BuildingAnalysis.get_job_logs(0)` method and specify a run number, starting at 0. For instance, if the first run failed, we call `analysis_1.explain(0)`\n",
    "\n",
    "By default, the fucntion gets 100 lines of logs. You can specify with `startFromHead=True` or `False` if you want the last lines or the first lines (end of simulation or beginning of simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3465ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logs = analysis_1.get_job_logs(1, limit=10, startFromHead=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937791f3",
   "metadata": {},
   "source": [
    "Another way of getting some information about a tricky job is to call the `describe_submitted_job` method with a run number. The dictionary method will display things nicely in the results. Look for keywords such as **status** and **statusReason**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.describe_submitted_job(0).dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321c6f7",
   "metadata": {},
   "source": [
    "### Saving and reloading an analysis\n",
    "\n",
    "So far, the analysis_1 object has been livnig in *memory*. It is good practice to serialise (write) the object in order to be able to reload it in the future. This is especially usefull if the server quits and needs to be launched again. Or if you want to share an anlysis with a colleague!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680b6b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_1.save(\"analysis_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1182e4",
   "metadata": {},
   "source": [
    "To reload an analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267700bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_schema import BuildingAnalysis\n",
    "\n",
    "with open(\"analysis_1.json\", \"r\") as f:\n",
    "    analysis_1 = BuildingAnalysis.model_validate_json(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f4193",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "## Retrieving results\n",
    "\n",
    "After an analysis has completed, runs that have succeeded (often all of them) can be retreived with the `get_sensitivity_results` method. If some of the runs have failed - maybe some parameter don't make sense and make EnergyPlus crash - they will simply not appear in the DataFrame.\n",
    "\n",
    "An Important step here is to determine the cooling COP and the heating COP of the system to calculate accurately the EUI, TEDI and CEDI metrics. This can be determined in the Characterization analyis. For now, we will assume the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e46630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis_1.get_sensitivity_results(COOLCOP=4, HEATCOP=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ac5aa",
   "metadata": {},
   "source": [
    "### Saving as a csv file\n",
    "\n",
    "To save the file to a csv, like with any pandas.DataFrame objects, simply call the `to_csv` method and pass a filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sensitivity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ed3fb",
   "metadata": {},
   "source": [
    "### Manipulating the data\n",
    "\n",
    "The sensitivity results are returned as a pandas.DataFrame object. It can be viewed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263e506",
   "metadata": {},
   "source": [
    "It can be filtered. Only show lines where the `EUI_kBtu_per_sqft` is lower than 44:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"EUI_kBtu_per_sqft\"] < 44]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58bf91",
   "metadata": {},
   "source": [
    "It can be plotted:\n",
    "\n",
    "### Plotting the Sensitivity results\n",
    "\n",
    "Below is the code to generate an *interactive* plot (you can pick the metric to view) which will eventually be included in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71eaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    \"EUI_kBtu_per_sqft\",\n",
    "    \"TEDI_kBtu_per_sqft\",\n",
    "    \"CEDI_kBtu_per_sqft\",\n",
    "    \"EDI_kBtu_per_sqft\",\n",
    "]\n",
    "\n",
    "nb_vars = df.Variable.unique().size\n",
    "\n",
    "\n",
    "def plot_func(metric):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nb_vars // 3 or 1, ncols=min(nb_vars, 3), sharey=True, figsize=(15, 10)\n",
    "    )\n",
    "    axes = axes.ravel()\n",
    "    ylim = (df[metric].values.min(), df[metric].values.max())\n",
    "    for i, (var, data) in enumerate(df.groupby(\"Variable\")):\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        if \"WINU\" in var:\n",
    "            data[var] = 1 / data[var]\n",
    "        # plot the lineplot first\n",
    "        ax = data.plot(\n",
    "            x=var,  # plot var a x axis\n",
    "            y=metric,  # plot metric a y axis\n",
    "            color=\"#1f77b4\",\n",
    "            label=var,\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        if \"WINU\" in var:\n",
    "            ax.set_xticks(data[var], labels=1 / data[var])\n",
    "        else:\n",
    "            ax.set_xticks(data[var])\n",
    "        # List of colors c for markers\n",
    "        c = (\n",
    "            data[[var, \"Baseline\"]]\n",
    "            .set_index(\"Baseline\")\n",
    "            .apply(lambda x: \"#b4d6e8\" if x.name == \"no\" else \"#1f77b4\", axis=1)\n",
    "            .tolist()\n",
    "        )\n",
    "        # Plot markers with scatter plot, second\n",
    "        data.plot.scatter(\n",
    "            x=var,\n",
    "            y=metric,\n",
    "            c=c,\n",
    "            marker=\"o\",\n",
    "            s=50,\n",
    "            edgecolors=\"#1f77b4\",\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        # Plot the horizontal line of the baseline\n",
    "        for h in data.loc[data[\"Baseline\"] == \"yes\", metric]:\n",
    "            ax.axhline(h, c=\"#eaeaea\", zorder=-1)\n",
    "        ax.set_ylabel(metric)  # set ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36afbcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(\n",
    "    plot_func,\n",
    "    metric=widgets.Dropdown(\n",
    "        options=METRICS,\n",
    "        index=0,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e81eaa",
   "metadata": {},
   "source": [
    "## Other API Hacks\n",
    "\n",
    "A couple interesting calls that can be made to the API using python commmands are detailed bellow: By the way, all the API entrypoints are detailed at [https://api.elementa.nyc/docs](https://api.elementa.nyc/docs).\n",
    "\n",
    "### Downloading one of the simulation files\n",
    "\n",
    "If you want to download the idf file generated for one of the runs, we can use the `/downloadfile/` entrypoint with a \"GET\" method. We need to provide the URL of the file. We can get that URL from the analysis Job attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_1.job.parameters.idf_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e495ba",
   "metadata": {},
   "source": [
    "By default, the generated idf model is saved in a *folder* called \"/idfs\", under the analysis id. In addition, the model filename always has the following form: `in_<run_numer>.idf`. Therefore, we can construct a URL and pass it as a parameter of the API. FYI, the [API documentations](https://api.elementa.nyc/docs#/default/download_file_downloadfile__get) tells us that the get method needs a `parameter` named `s3_file_path`. This is what we put below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30451a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = analysis_1.Client.client.get(\n",
    "    \"/downloadfile/\",\n",
    "    params={\"s3_file_path\": f\"{analysis_1.job.parameters.idf_output_dir}in_0.idf\"},\n",
    ")\n",
    "\n",
    "# save the downloaded content to a file named `in_0.idf`\n",
    "with open(\"in_0.idf\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a46364",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_aws = IDF(\"in_0.idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_aws.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a6c88",
   "metadata": {},
   "source": [
    "We can then write a function that calculates the total envelope area (roofs and walls) to be able to calculate the Heat_Loss_Form_Factor of the building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eppy.bunch_subclass import EpBunch\n",
    "\n",
    "\n",
    "def total_envelope_area(self):\n",
    "    \"\"\"Get the total gross envelope area including windows [m2].\n",
    "\n",
    "    Note:\n",
    "        The envelope is consisted of surfaces that have an outside boundary\n",
    "        condition different then `Adiabatic` or `Surface` or that participate in\n",
    "        the heat exchange with the exterior.\n",
    "\n",
    "    \"\"\"\n",
    "    total_area = 0\n",
    "    area = 0\n",
    "    zones = self.idfobjects[\"ZONE\"]\n",
    "    zone: EpBunch\n",
    "    for zone in zones:\n",
    "        for surface in zone.zonesurfaces:\n",
    "            if hasattr(surface, \"tilt\"):\n",
    "                if surface.tilt == 180.0:\n",
    "                    multiplier = float(zone.Multiplier if zone.Multiplier != \"\" else 1)\n",
    "                    area += surface.area * multiplier\n",
    "    self._area_total = area\n",
    "    for surface in self.getsurfaces():\n",
    "        if surface.Outside_Boundary_Condition.lower() in [\"adiabatic\", \"surface\"]:\n",
    "            continue\n",
    "        zone = surface.get_referenced_object(\"Zone_Name\")\n",
    "        multiplier = float(zone.Multiplier if zone.Multiplier != \"\" else 1)\n",
    "        total_area += surface.area * multiplier\n",
    "    return total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef34dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF.total_envelope_area = (\n",
    "    total_envelope_area  # assign the function to the class itself.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166dc9a",
   "metadata": {},
   "source": [
    "Note that the `total_building_area` is a property and not a function, that is why it is not called with parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ade7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_loss_form_factor = idf.total_envelope_area() / idf.total_building_area\n",
    "heat_loss_form_factor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "323px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
